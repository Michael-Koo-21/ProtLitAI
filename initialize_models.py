#!/usr/bin/env python3
"""
ML Model Initialization Script for ProtLitAI
Downloads and initializes all required ML models for production use
"""

import sys
import time
from pathlib import Path
from typing import Dict, Any

# Add src to Python path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from core.config import config
from core.logging import get_logger
from processing.ml_models import get_model_manager


def format_size(bytes_size: int) -> str:
    """Format byte size to human readable string."""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if bytes_size < 1024.0:
            return f"{bytes_size:.1f} {unit}"
        bytes_size /= 1024.0
    return f"{bytes_size:.1f} TB"


def check_system_requirements() -> Dict[str, Any]:
    """Check system requirements for ML model initialization."""
    logger = get_logger("model_init")
    
    print("ğŸ” Checking System Requirements")
    print("-" * 50)
    
    requirements = {
        "pytorch_available": False,
        "mps_available": False,
        "disk_space": 0,
        "memory_info": {},
        "status": "unknown"
    }
    
    try:
        # Check PyTorch
        import torch
        requirements["pytorch_available"] = True
        print(f"âœ… PyTorch {torch.__version__} installed")
        
        # Check MPS (Metal Performance Shaders)
        if torch.backends.mps.is_available():
            requirements["mps_available"] = True
            print(f"âœ… MPS acceleration available")
        else:
            print(f"âš ï¸  MPS acceleration not available")
        
        # Check disk space
        import shutil
        disk_usage = shutil.disk_usage(Path.cwd())
        requirements["disk_space"] = disk_usage.free
        print(f"âœ… Available disk space: {format_size(disk_usage.free)}")
        
        if disk_usage.free < 5 * 1024 * 1024 * 1024:  # 5GB
            print(f"âš ï¸  Warning: Less than 5GB free space available")
        
        # Check memory
        import psutil
        memory = psutil.virtual_memory()
        requirements["memory_info"] = {
            "total": memory.total,
            "available": memory.available,
            "percent": memory.percent
        }
        print(f"âœ… Available memory: {format_size(memory.available)} ({100-memory.percent:.1f}% free)")
        
        # Overall status
        if requirements["pytorch_available"] and disk_usage.free > 2 * 1024 * 1024 * 1024:
            requirements["status"] = "ready"
        else:
            requirements["status"] = "insufficient"
        
    except ImportError as e:
        print(f"âŒ Missing dependency: {e}")
        requirements["status"] = "missing_deps"
    except Exception as e:
        print(f"âŒ System check failed: {e}")
        requirements["status"] = "error"
    
    print(f"\nğŸ“Š System Status: {requirements['status'].upper()}")
    return requirements


def initialize_models() -> Dict[str, Any]:
    """Initialize all required ML models."""
    logger = get_logger("model_init")
    
    print("\nğŸ¤– Initializing ML Models")
    print("-" * 50)
    
    results = {
        "sentence_transformer": {"status": "pending", "time": 0, "error": None},
        "spacy_model": {"status": "pending", "time": 0, "error": None},
        "total_time": 0,
        "overall_status": "pending"
    }
    
    start_time = time.time()
    
    try:
        # Get model manager
        print("ğŸ“¦ Creating model manager...")
        manager = get_model_manager()
        print("âœ… Model manager created successfully")
        
        # Initialize sentence transformer
        print("\nğŸ”¤ Initializing Sentence Transformer model...")
        print("   ğŸ“¥ This may take several minutes on first run...")
        st_start = time.time()
        
        try:
            embedding_model = manager.load_embedding_model()
            st_time = time.time() - st_start
            results["sentence_transformer"] = {
                "status": "success",
                "time": st_time,
                "error": None,
                "model_name": config.settings.embedding_model
            }
            print(f"âœ… Sentence Transformer loaded in {st_time:.1f}s")
            
            # Test embedding generation
            print("   ğŸ§ª Testing embedding generation...")
            test_embedding = manager.generate_embeddings(["Test protein design paper"])
            print(f"   âœ… Test embedding: {test_embedding.shape} dimensions")
            
        except Exception as e:
            results["sentence_transformer"] = {
                "status": "failed",
                "time": time.time() - st_start,
                "error": str(e)
            }
            print(f"âŒ Sentence Transformer failed: {e}")
        
        # Initialize spaCy model
        print("\nğŸ”¬ Initializing spaCy biomedical model...")
        print("   ğŸ“¥ This may take time on first run...")
        spacy_start = time.time()
        
        try:
            spacy_model = manager.load_spacy_model()
            spacy_time = time.time() - spacy_start
            results["spacy_model"] = {
                "status": "success",
                "time": spacy_time,
                "error": None,
                "model_name": config.settings.spacy_model
            }
            print(f"âœ… spaCy model loaded in {spacy_time:.1f}s")
            
            # Test entity extraction
            print("   ğŸ§ª Testing entity extraction...")
            test_entities = manager.extract_entities(["EGFR protein design using machine learning"])
            print(f"   âœ… Test entities extracted: {len(test_entities[0]) if test_entities else 0} entities")
            
        except Exception as e:
            results["spacy_model"] = {
                "status": "failed",
                "time": time.time() - spacy_start,
                "error": str(e)
            }
            print(f"âŒ spaCy model failed: {e}")
        
        # Warm up models
        print("\nğŸ”¥ Warming up models...")
        warmup_start = time.time()
        try:
            manager.warmup_models()
            warmup_time = time.time() - warmup_start
            print(f"âœ… Models warmed up in {warmup_time:.1f}s")
        except Exception as e:
            print(f"âš ï¸  Model warmup failed: {e}")
        
        # Get performance stats
        try:
            stats = manager.get_performance_stats()
            print(f"\nğŸ“Š Performance Statistics:")
            print(f"   Device: {stats.get('device', 'unknown')}")
            print(f"   Memory usage: {stats.get('memory_usage', 'unknown')}")
        except Exception as e:
            print(f"âš ï¸  Could not get performance stats: {e}")
    
    except Exception as e:
        print(f"âŒ Model initialization failed: {e}")
        results["overall_status"] = "failed"
        results["error"] = str(e)
        return results
    
    # Calculate total time and overall status
    total_time = time.time() - start_time
    results["total_time"] = total_time
    
    success_count = sum(1 for r in [results["sentence_transformer"], results["spacy_model"]] 
                       if r["status"] == "success")
    
    if success_count == 2:
        results["overall_status"] = "success"
    elif success_count == 1:
        results["overall_status"] = "partial"
    else:
        results["overall_status"] = "failed"
    
    return results


def main():
    """Main entry point."""
    print("ğŸš€ ProtLitAI ML Model Initialization")
    print("=" * 60)
    
    # Check system requirements
    requirements = check_system_requirements()
    
    if requirements["status"] not in ["ready"]:
        print(f"\nâŒ System not ready for model initialization: {requirements['status']}")
        if requirements["status"] == "insufficient":
            print("   Please ensure you have at least 2GB free disk space")
        return 1
    
    # Initialize models
    results = initialize_models()
    
    # Print final summary
    print("\n" + "=" * 60)
    print("ğŸ INITIALIZATION SUMMARY")
    print("=" * 60)
    
    print(f"Overall Status: {results['overall_status'].upper()}")
    print(f"Total Time: {results['total_time']:.1f} seconds")
    print()
    
    print("Component Results:")
    for component, result in results.items():
        if isinstance(result, dict) and "status" in result:
            status_icon = "âœ…" if result["status"] == "success" else "âŒ"
            print(f"  {status_icon} {component}: {result['status']} ({result['time']:.1f}s)")
            if result.get("error"):
                print(f"      Error: {result['error']}")
    
    if results["overall_status"] == "success":
        print("\nğŸ‰ All models initialized successfully!")
        print("   ProtLitAI is ready for production use.")
    elif results["overall_status"] == "partial":
        print("\nâš ï¸  Some models failed to initialize.")
        print("   ProtLitAI may have limited functionality.")
    else:
        print("\nâŒ Model initialization failed.")
        print("   Please check the errors above and try again.")
        return 1
    
    print(f"\nğŸ’¡ Next Steps:")
    print(f"   - Run production literature collection: python production_collection.py")
    print(f"   - Launch UI application: python -m src.ui.app")
    print(f"   - Check system status: python test_end_to_end.py")
    
    return 0


if __name__ == "__main__":
    try:
        exit_code = main()
        sys.exit(exit_code)
    except KeyboardInterrupt:
        print("\n\nInitialization interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\nInitialization failed with error: {e}")
        sys.exit(1)